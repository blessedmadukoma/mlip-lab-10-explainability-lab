{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10: Explainability with Alibi\n",
    "In this lab, you'll learn about the Alibi Explain library and implement global and local explanations of tabular and image classification models.\n",
    "\n",
    "Alibi Explain is an open source Python library aimed at machine learning model inspection and interpretation. The focus of the library is to provide high-quality implementations of black-box, white-box, local and global explanation methods for classification and regression models.\n",
    "\n",
    "Complete all the Deliverables mentioned below and show it to a TA for credit.\n",
    "\n",
    "## Deliverables\n",
    "- Finish all the TODOs in Section 2\n",
    "- Generate PD Plots. Discuss your findings about model performance with the TA and answer Q1, Q2, and Q3:\n",
    "     - Q1: Which features have higher importance in the prediction? (Section 2.1)\n",
    "     - Q2: What can you conclude with the PD plots? (Section 2.2)\n",
    "     - Q3: Discuss with the TA the results (heatmaps). (Section 2.2)\n",
    "- Show final results  about the Anchor parameters and discuss them with the TA.\n",
    "- Complete the SHAP section & discuss your findings with the TA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "Clone this repository and run all cells in the notebook.\n",
    "\n",
    "### Install Dependencies\n",
    "\n",
    "For this assignment, make sure you have the required packages installed.\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "(If there are any major unsolvable issues prefer running this notebook on Google Colaboratory)\n",
    "\n",
    "### Possible Issues with installing Alibi\n",
    "`TypeError: issubclass() arg 1 must be a class` \\\n",
    "**Solution:** https://stackoverflow.com/questions/76313592/import-langchain-error-typeerror-issubclass-arg-1-must-be-a-class\n",
    "<br><br>\n",
    "If there's any more issues, please contact a TA to update this list (with a solution if its solved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from alibi.explainers import PartialDependence, plot_pd, plot_pd_variance\n",
    "from alibi.explainers import PartialDependenceVariance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Data + Modeling\n",
    "In this section, we will be setting up our data, perform some preprocessing and train a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Fetching the Dataset\n",
    "We are going to use the The Boston Housing Dataset in the next experiment.\n",
    "https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\n",
    "\n",
    "\n",
    "There are 14 attributes in each case of the dataset:\n",
    "- CRIM - per capita crime rate by town\n",
    "- ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS - proportion of non-retail business acres per town.\n",
    "- CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "- NOX - nitric oxides concentration (parts per 10 million)\n",
    "- RM - average number of rooms per dwelling\n",
    "- AGE - proportion of owner-occupied units built prior to 1940\n",
    "- DIS - weighted distances to five Boston employment centres\n",
    "- RAD - index of accessibility to radial highways\n",
    "- TAX - full-value property-tax rate per $10,000\n",
    "- PTRATIO - pupil-teacher ratio by town\n",
    "- B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- LSTAT - % lower status of the population\n",
    "- MEDV - Median value of owner-occupied homes in $1000's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('BostonHousing.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Dataset Preprocessing\n",
    "\n",
    "Run the following code necessary to pre-process the data for alibi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract feature names\n",
    "feature_names = df.columns.tolist()\n",
    "target_feature = 'medv'\n",
    "feature_names.remove(target_feature)\n",
    "\n",
    "# define target names\n",
    "target_names = [target_feature]\n",
    "\n",
    "#  define categorical columns\n",
    "categorical_columns_names = []\n",
    "\n",
    "# define categorical and numerical indices for later preprocessing\n",
    "categorical_columns_indices = [feature_names.index(cn) for cn in categorical_columns_names]\n",
    "numerical_columns_indices = [feature_names.index(fn) for fn in feature_names if fn not in categorical_columns_names]\n",
    "\n",
    "# extract data\n",
    "X = df[feature_names]\n",
    "# define target column\n",
    "y = df[target_feature]\n",
    "\n",
    "# split data in train & test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit the original encoder\n",
    "oe = OrdinalEncoder().fit(X_train[categorical_columns_names])\n",
    "\n",
    "# transform the categorical columns to ordinal encoding\n",
    "X_train.loc[:, categorical_columns_names] = oe.transform(X_train[categorical_columns_names])\n",
    "X_test.loc[:, categorical_columns_names] = oe.transform(X_test[categorical_columns_names])\n",
    "\n",
    "# convert data to numpy\n",
    "X_train, y_train = X_train.to_numpy(), y_train.to_numpy()\n",
    "X_test, y_test = X_test.to_numpy(), y_test.to_numpy()\n",
    "\n",
    "# define categorical mappings\n",
    "categorical_names = {i: list(v) for (i, v) in zip(categorical_columns_indices, oe.categories_)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define numerical standard sclaer\n",
    "num_transf = StandardScaler()\n",
    "\n",
    "# define categorical one-hot encoder\n",
    "cat_transf = OneHotEncoder(\n",
    "    categories=[range(len(x)) for x in categorical_names.values()],\n",
    "    handle_unknown='ignore',\n",
    ")\n",
    "\n",
    "# define preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', cat_transf, categorical_columns_indices),\n",
    "        ('num', num_transf, numerical_columns_indices),\n",
    "    ],\n",
    "    sparse_threshold=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit preprocessor\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "# preprocess train and test datasets\n",
    "X_train_ohe = preprocessor.transform(X_train)\n",
    "X_test_ohe = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Training the Model\n",
    "Run the cell to fit the model to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define and fit regressor - feel free to play with the hyperparameters\n",
    "predictor = RandomForestRegressor(random_state=0)\n",
    "predictor.fit(X_train_ohe, y_train)\n",
    "\n",
    "# compute scores\n",
    "print('Train score: %.2f' % (predictor.score(X_train_ohe, y_train)))\n",
    "print('Test score: %.2f' % (predictor.score(X_test_ohe, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Explainability with Alibi\n",
    "In this section, we will be finally using Alibi to explain our trained model using different techniques. Fill in the TODOs and generate plots where required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Prediction Function - Includes pipeline from preprocessing to prediction\n",
    "prediction_fn = lambda x: predictor.predict(preprocessor.transform(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing Explanations\n",
    "We will finally be computing explanations for selected features. Play around with different methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Partial Dependence Variance (PDV)  - Feature Importance\n",
    "\n",
    "Partial Dependence Variance is a method to compute the global feature importance or the feature interaction of a pair of features.\n",
    "\n",
    "Complete the code below and answer Q1\n",
    "\n",
    "**Q1: Which features have higher importance in the prediction?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Determine which features are more important\n",
    "# suggestion: Use PartialDependenceVariance class and explain function using the argument method='importance'\n",
    "\n",
    "#explainer = ...\n",
    "#exp_importance = ...\n",
    "\n",
    "# plot the results using \n",
    "#plot_pd_variance(exp=exp_importance)\n",
    "#plot_pd_variance(exp=exp_importance, summarise=False,  fig_kw={'figheight': 15, 'figwidth': 10})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Partial Dependence (PD)\n",
    "\n",
    "Partial Dependence is a method to visualize the marginal effect that one or two features have on the predicted outcome of a machine learning model.\n",
    "\n",
    "By inspecting the PD plots, one can understand whether the relation between a feature/pair of features is, for example, a simple linear or quadratic relation, whether it presents a monotonically increasing or decreasing trend, or reveal a more complex response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing Explanations\n",
    "We will finally be computing explanations. You can try different modes of `kind` to see different visualizations. (Suggestion: use `both` to visualize all data)\n",
    "\n",
    "As per the documentation,\n",
    "> `kind` - If set to `average`, then only the partial dependence (PD) averaged across all samples from the dataset is returned. If set to `individual`, then only the individual conditional expectation (ICE) is returned for each individual from the dataset. Otherwise, if set to `both`, then both the PD and the ICE are returned.\n",
    "\n",
    "\n",
    "Run the following code with all features and also selecting some specific features.\n",
    "\n",
    "**Q2: What can you conclude?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define explainer\n",
    "explainer_pd = PartialDependence(predictor=prediction_fn,\n",
    "                       feature_names=feature_names,\n",
    "                       categorical_names=categorical_names,\n",
    "                       target_names=target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also compute explanations for selected features.\n",
    "# Hint - Select Column Indices = feature_names.index(\"COLUMN_NAME\")\n",
    "# zn\tindus\tchas\tnox\trm\tage\tdis\trad\ttax\tptratio\tb\tlstat\tmedv\n",
    "\n",
    "# TODO - Select features you wish to compute explanations for\n",
    "# Hint - Select Column Indices = feature_names.index(\"COLUMN_NAME\")\n",
    "features = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute explanations\n",
    "# exp = explainer_pd.explain(X=X_train,\n",
    "#                         #features=features,\n",
    "#                         kind='both') # kind = [both, individual, average]\n",
    "\n",
    "# # plot partial dependece curves\n",
    "# # this setup should work for any mode of kind, feel free to alter this to better suit your plot view.\n",
    "# plot_pd(exp=exp,\n",
    "#         n_cols=3,\n",
    "#         n_ice=50,\n",
    "#         sharey='row',\n",
    "#         center = True,\n",
    "#         fig_kw={'figheight': 15, 'figwidth': 10});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Partial Dependence for Two Features\n",
    "Choose pairs of features to visualize their relationships and interactions with each other. These plots may be a bit confusing so try your best to explain whatever you understand to the TA.\n",
    "We suggest to select a feature with high  and low importance. \n",
    "You can also try different combinations of features in order to get better conclusion.\n",
    "\n",
    "**Q3: Discuss with the TA the results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: select combination of features\n",
    "FEATURE1 = ''\n",
    "FEATURE2 = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = [(feature_names.index(FEATURE1), feature_names.index(FEATURE2))]\n",
    "\n",
    "# compute explanations\n",
    "comb_exp = explainer_pd.explain(X=X_train,\n",
    "                        features=combined_features,\n",
    "                        kind='average',\n",
    "                        grid_resolution=25) # kind = [both, individual, average]\n",
    "\n",
    "# plot partial dependece curves\n",
    "plot_pd(exp=comb_exp,\n",
    "        n_cols=3,\n",
    "        n_ice=50,\n",
    "        sharey='row',\n",
    "        center = True,\n",
    "        fig_kw={'figheight': 5, 'figwidth': 10});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Anchors\n",
    "This algorithm provides model-agnostic (black box) and human interpretable explanations suitable for classification models applied to images, text and tabular data. The idea behind anchors is to explain the behaviour of complex models with high-precision rules called anchors. These anchors are locally sufficient conditions to ensure a certain prediction with a high degree of confidence. Run all the cells and try different parameters to see how this algorithm works.\n",
    "\n",
    "We will be explaining predictions from the ImageNet model on the cats dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from alibi.datasets import load_cats\n",
    "from alibi.explainers import AnchorImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your image\n",
    "\n",
    "# You are free to play around with other images. \n",
    "# Here are two pictures of Professor Bogdan's beautiful cat.\n",
    "img1_path = \"hyPURRmeter_fineMEOWing.jpg\"\n",
    "img2_path = \"your_TA.jpg\"\n",
    "\n",
    "def load_and_preprocess(img_path):\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_preprocessed = preprocess_input(np.expand_dims(img_array, axis=0))\n",
    "    return img_array, img_preprocessed\n",
    "\n",
    "# Load and preprocess\n",
    "img1 = image.load_img(img1_path, target_size=(299, 299))\n",
    "img1_array = image.img_to_array(img1)\n",
    "img1_preprocessed = preprocess_input(np.expand_dims(img1_array, axis=0))\n",
    "\n",
    "# Display both images\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img1_array.astype('uint8'))\n",
    "plt.title(\"Image 1\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img2_array.astype('uint8'))\n",
    "plt.title(\"Image 2\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pre-trained model\n",
    "model = InceptionV3(weights='imagenet')\n",
    "predict_fn = lambda x: model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check model predictions for both images.\n",
    "for idx, (arr, prep) in enumerate([(img1_array, img1_preprocessed), (img2_array, img2_preprocessed)], start=1):\n",
    "    preds = model.predict(prep)\n",
    "    decoded = decode_predictions(preds, top=3)[0]\n",
    "    print(f\"\\nTop predictions for Image {idx}:\")\n",
    "    for _, label, prob in decoded:\n",
    "        print(f\"  {label:20s}: {prob:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and run anchorImage explainer\n",
    "image_shape = (299, 299, 3)\n",
    "segmentation_fn = 'slic'  # Superpixel segmentation\n",
    "kwargs = {'n_segments': 15, 'compactness': 20, 'sigma': .5, 'start_label': 0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = AnchorImage(\n",
    "    predict_fn,\n",
    "    image_shape=image_shape,\n",
    "    segmentation_fn=segmentation_fn,\n",
    "    segmentation_kwargs=kwargs,\n",
    "    images_background=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose an image to explain\n",
    "\n",
    "image_to_explain = img1_preprocessed[0]  # or img2_preprocessed[0]\n",
    "np.random.seed(0)\n",
    "\n",
    "explanation = explainer.explain(image_to_explain, threshold=.95, p_sample=.5, tau=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img1_array.astype('uint8'))\n",
    "plt.title(\"Original Image\", fontsize=14)\n",
    "plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(explanation.anchor)\n",
    "plt.title(\"Anchor Explanation\", fontsize=14)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(explanation.segments)\n",
    "plt.title(\"Segmentation Map\", fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions:\n",
    "1. What part of your image did the Anchor explainer focus on?\n",
    "2. Does the highlighted region make sense when you compare it to the model's predicted label?\n",
    "3. What does it mean if the highlighted region seems unrelated to the object?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 SHAP\n",
    "SHAP is a unified framework for interpreting predictions based on Shapley values from cooperative game theory.\n",
    "It attributes the prediction of a model to each input feature by quantifying how much that feature contributed to increasing or decreasing the final prediction compared to the model’s average output.\n",
    "In other words, SHAP tells us:\n",
    "“If I remove or change this feature, how would the model’s prediction change?”\n",
    "SHAP values are additive, meaning that for each prediction, the sum of all feature contributions equals the model’s output minus the baseline (average) prediction.\n",
    "This makes SHAP both mathematically grounded and visually interpretable.\n",
    "In this section, you will:\n",
    "1. Generate global feature importance using SHAP summary plots.\n",
    "2. Analyze local explanations for a specific instance using waterfall plots.\n",
    "3. Compare SHAP’s results with your earlier Partial Dependence and Anchor explanations to see whether they agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define SHAP explainer for the Random Forest regressor\n",
    "shap_explainer = shap.Explainer(predictor, X_train_ohe)\n",
    "\n",
    "# Compute SHAP values\n",
    "shap_values = shap_explainer(X_test_ohe)\n",
    "\n",
    "# Global feature importance\n",
    "shap.summary_plot(shap_values, X_test, feature_names=feature_names)\n",
    "# plt.title(\"Global SHAP Feature Importance\")\n",
    "# plt.show()\n",
    "\n",
    "# Local explanation for one instance\n",
    "idx = 5\n",
    "shap.plots.waterfall(shap_values[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Reflection & comparison\n",
    "You have now explored three complementary ways to understand your model’s behavior:\n",
    "Partial Dependence (PD): shows average feature effects (global trend).\n",
    "Anchors: provides human-readable rules explaining specific predictions (local).\n",
    "SHAP: quantifies feature contributions for each prediction (both global and local).\n",
    "Each method offers a different lens:\n",
    "1. PD plots summarize what the model learns overall,\n",
    "2. Anchors explain why a single decision was made, and\n",
    "3. SHAP connects both by showing how much each feature contributed numerically.\n",
    "Use this final section to connect the dots between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions to answer:\n",
    "\n",
    "1. Do any of the top features raise ethical or fairness concerns?\n",
    "Could the model be relying on socioeconomic or location-based variables in ways that might bias predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Do SHAP’s most important features agree with those found by PD plots or Anchor explanations?\n",
    "If they differ, why might that happen?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Write a short paragraph (3 sentences max) summarizing what your model relies on and how confident you are in its interpretability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "1. https://docs.seldon.io/projects/alibi/en/stable/examples/pdp_regression_bike.html\n",
    "2. https://docs.seldon.io/projects/alibi/en/stable/methods/PartialDependence.html\n",
    "3. https://docs.seldon.io/projects/alibi/en/stable/examples/anchor_image_imagenet.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
